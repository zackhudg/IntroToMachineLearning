{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❗Before starting, make sure the following files are in the same directory as your Jupyter notebook:\n",
    " - train_data.pgz\n",
    " - test_data.pgz\n",
    " - vocab_list.pgz\n",
    " - train_id.pgz\n",
    " \n",
    " You can download these files from `Sakai > Resources > HW1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Ridge logistic regression\n",
    "In this homework, the objective is to train a model for a **<span style='background :greenyellow'>binary classification** task. Specifically, the task is to classify movie reviews (submitted by users on IMDb) as either positive (\"It was a great film!\") or negative (\"Absolute trash!\").\n",
    "\n",
    "### The dataset\n",
    "Regarding the data, the reviews are *not* represented as raw text, but instead as word-frequency vectors. That is, in their raw form, each review is represented by a 1000-dimensional real-valued vector. (Note that we have a vocab list of 1000 words.) Given one \"review\" vector, each value within that vector is a normalized frequency (or count) of that word in the given review. \n",
    "\n",
    "Each word-frequency vector is paired with a label, either -1 (negative, bad) or 1 (positive, good).\n",
    "\n",
    "### The model\n",
    "You will implement a **<span style='background :greenyellow'>ridge-regularized logistic regression** model, trained by gradient ascent, to solve this binary classification problem. It will be trained on the provided training set. You'll try out different values for the regularization parameter (or \"ridge term\"), and report the corresponding accuracies on the validation set.\n",
    "\n",
    "Once the model is trained to satisfaction, you will evaluate the model's performance on the test set, and report which vocab words were the most \"confusing\" to the model for a given review, that is, words that lead to that review being misclassified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "import gzip\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import urllib\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "    kwargs = {}\n",
    "except:\n",
    "    import _pickle as pickle\n",
    "    kwargs = {'encoding':'bytes'}\n",
    "    \n",
    "versionName = sys.version_info\n",
    "if versionName[0] == 2:\n",
    "    import urllib as U\n",
    "elif versionName[0] == 3:\n",
    "    import urllib.request as U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = pickle.load( gzip.open( \"train_data.pgz\", \"rb\" ), **kwargs )\n",
    "test_data = pickle.load( gzip.open( \"test_data.pgz\", \"rb\" ),**kwargs )\n",
    "vocab_list = pickle.load( gzip.open( \"vocab_list.pgz\", \"rb\" ),**kwargs )\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "\n",
    "trainData = train_data[:10000, :]\n",
    "validData = train_data[10000:15000, :]\n",
    "trainLabel = train_label[:10000]\n",
    "validLabel = train_label[10000:15000]\n",
    "testData = test_data[:10000, :]\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Relevant and super important definitions\n",
    "\n",
    "Data are given as $D = {(\\mathbf{x}_i, y_i):, i = 1...n}$, where $y_i \\in \\{-1, +1\\}$, and $\\mathbf{x}_i \\in R^p$. </br>\n",
    "There are $n$ samples. Each sample has $p$ features. </br>\n",
    "\n",
    "For logistic regression, \n",
    "* We have model parameters: $\\mathbf{w} \\in R^p$ for the weight term, and $b$ for the bias term.\n",
    "<br>\n",
    "* For a sample $x$ and its label $y$, we have the following probability function: \n",
    "\n",
    "   $\\large p(y|\\mathbf{x}, \\mathbf{w}, b) = \\frac{1}{1+exp\\{-y(\\mathbf{w} \\cdot \\mathbf{x} + b)\\}}$ \n",
    "<br>\n",
    "* We will include the bias term in the weight vector. Therefore, our feature and weight vectors will be defined as follows: \n",
    "\n",
    "   $\\large x' = \\begin{bmatrix} 1\\\\ x \\end{bmatrix}$ and $\\large \\mathbf{w}' =  \\begin{bmatrix} b\\\\ \\mathbf{w} \\end{bmatrix}$\n",
    "<br>\n",
    "\n",
    "    * But for brevity, we will still use notations $x, \\mathbf{w}$ as $x', \\mathbf{w}'$. \n",
    "    * The first entry of the vector $\\mathbf{w}'$ is the bias term and the remaining entries are feature weights. In code, you can use `w[0]` to access the bias term and `w[1:]` to access the feature weights. \n",
    "    * We do this concatenation for you in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation such that the first feature becomes the bias term.\n",
    "train_data_pad = np.concatenate((np.ones((trainData.shape[0], 1)), trainData), axis=1)\n",
    "test_data_pad = np.concatenate((np.ones((testData.shape[0], 1)), testData), axis=1)\n",
    "valid_data_pad = np.concatenate((np.ones((validData.shape[0], 1)), validData), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Likelihood expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **<span style='background :yellow'>(1pt)</span>** <font color=blue> Write out the likelihood function, $\\mathcal{L}(\\mathbf{w})$, of logistic regression. </font> (Your variables will not be the ones used in lecture. Refer back to the definitions given in Section 0.)\n",
    "<br><br>\n",
    "\n",
    "<font color=blue>  \n",
    "    \n",
    "$$ \n",
    "\\mathcal{L}(\\mathbf{w}) = \\prod_i \\frac{1}{1+exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i} + b)\\}}\n",
    "$$\n",
    "\n",
    "\n",
    "    \n",
    "2) **<span style='background :yellow'>(1pt)</span>** <font color=blue> Write out the log-likelihood function, $\\mathcal{L}\\mathcal{L}(\\mathbf{w})$. <font color=black> (i.e. Take the log of your answer to Question 1.) \n",
    "<br><br>\n",
    "    \n",
    "<font color=blue>   \n",
    "    \n",
    "$$ \n",
    "\\mathcal{L}\\mathcal{L}(\\mathbf{w}) = -\\sum_i log\\{{1+exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i} + b)\\}}\\} \n",
    "$$\n",
    "    \n",
    "    \n",
    "    \n",
    "3) **<span style='background :yellow'>(1pt)</span>** <font color=blue> Add on a ridge penalty term to the log-likelihood function. <font color=black> The weight of the ridge penalty is $\\alpha$. <br> \n",
    "(*Hint: Do not include $w_0$ in the ridge term!!*)\n",
    "<br><br>\n",
    "    \n",
    "<font color=blue>   \n",
    "    \n",
    "$$    \n",
    "P\\mathcal{L}\\mathcal{L}(\\mathbf{w}) = -\\sum_i log\\{{1+exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i} + b)\\}}\\}   - \\frac{\\alpha}{2}\\sum_{j=1}^{p} w_j^{2}\n",
    "$$\n",
    "    \n",
    "    \n",
    "4) **<span style='background :yellow'>(1pt)</span>** <font color=blue> In the cell below, replace the ellipses (three of them) with code to complete `loglikelihood`, a function that computes the ridge-regularized log-likelihood for `w` given the data `X`,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(w, X, y, alpha): \n",
    "    # w is a vector, X is a n*p matrix, and y is a vector.\n",
    "    tmp = 1. + np.exp( -y*(X.dot(w)) )                          ## FILL-IN-THE-BLANK ## \n",
    "    return -np.sum( np.log(tmp) ) - (alpha/2.)*np.sum( w[1:]**2 )   ## FILL-IN-THE-BLANK ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test? True\n"
     ]
    }
   ],
   "source": [
    "# Small test to check that function works.\n",
    "np.random.seed(1)\n",
    "X = np.random.randn(2,3)\n",
    "y = np.array([1,-1])\n",
    "w = np.ones(3)\n",
    "w[[1]] = -1\n",
    "\n",
    "ur_answer = loglikelihood(w, X, y, 1)\n",
    "expected =  -np.log(1+np.exp(-1*(X[0,0]-X[0,1]+X[0,2]))) \\\n",
    "- np.log(1+np.exp(1*(X[1,0]-X[1,1]+X[1,2]))) -1/2.*np.sum(w[1:]**2)\n",
    "\n",
    "\n",
    "did_u_pass = (ur_answer==expected)\n",
    "\n",
    "print(f\"Passed test? {did_u_pass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Gradient ascent derivation\n",
    "\n",
    "In order to optimize the log-likelihood function, we want to take its derivative w.r.t. each parameter in $\\mathbf{w}$, and then update $\\mathbf{w}$ according to the direction of the resultant gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$    \n",
    "P\\mathcal{L}\\mathcal{L}(\\mathbf{w}) = -\\sum_i log\\{{1+exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i} + b)\\}}\\}   - \\frac{\\alpha}{2}\\sum_{j=1}^{p} w_j^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) **<span style='background :yellow'>(1pt)</span>** <font color=blue> Write out the derivative of the ridge-penalized log-likelihood function (your answer to Question 3) w.r.t. **both $w_0$ and $w_j$**. </font> (*Hint: Remember that the bias term is $w_0$. Treat it separately from the rest of $w_j$, $j\\in\\{1,...,p\\}$!!*)\n",
    "<br><br>\n",
    "    \n",
    "<font color=blue>   \n",
    "    \n",
    "\n",
    "$$\n",
    "\\frac{\\partial P\\mathcal{L}\\mathcal{L}(\\mathbf{w})}{ \\partial w_0} = \\sum_i \\frac {exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\} * y_i} {1 + exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\}} \\\\\n",
    "\\frac{\\partial P\\mathcal{L}\\mathcal{L}(\\mathbf{w})}{ \\partial w_j} = \\sum_i \\frac {exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\} * y_i x_{i j}} {1 + exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\}}  - \\alpha w_j \\quad, j>0 \\\\\n",
    "$$\n",
    "    \n",
    "    \n",
    "6) **<span style='background :yellow'>(1pt)</span>**  Write out the gradient of the log-likelihood function.\n",
    "<br><br>\n",
    "    \n",
    "<font color=blue>   \n",
    "    \n",
    "$$ \n",
    "\\nabla P\\mathcal{L}\\mathcal{L}(\\mathbf{w}) = \\sum_i \\frac {exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\}} {1 + exp\\{-y_i(\\mathbf{w} \\cdot \\mathbf{x_i})\\}} y_i\\begin{bmatrix}  1 \\\\x_{i j} \\\\\\vdots \\\\  \\end{bmatrix} - \\begin{bmatrix} 0 \\\\\\alpha w_j  \\\\\\vdots \\\\  \\end{bmatrix}\n",
    "$$\n",
    "    \n",
    "    \n",
    "7) **<span style='background :yellow'>(1pt)</span>**  In the cell below, replace the ellipses (six of them) to update the `loglikelihood`  function such that it returns both the loglikelihood and the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(w, X, y, alpha): \n",
    "    tmp = 1. + np.exp( -y*(X.dot(w))  )        ## FILL-IN-THE-BLANK ## \n",
    "    prob = 1./tmp\n",
    "    X = X.T \n",
    "    #gradVal = np.dot(prob,(tmp-1).dot(y))       ## FILL-IN-THE-BLANK ## \n",
    "    gradVal = np.dot((tmp-1)*y*X, prob)\n",
    "    penalty = alpha/2.*np.sum(w**2)  ## FILL-IN-THE-BLANK ## \n",
    "    gradPenalty = -alpha*w              ## FILL-IN-THE-BLANK ## \n",
    "    gradPenalty[0] = 0            ## FILL-IN-THE-BLANK ## \n",
    "    \n",
    "    \n",
    "    return -np.sum( np.log( tmp ) ) - penalty, gradVal + gradPenalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check your `loglikelihood` function by comparing the gradient it computes to numerical answers.\n",
    "<br>\n",
    "<font color=blue>\n",
    "Run the code below. If you pass, you get the point for Question 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test? True\n"
     ]
    }
   ],
   "source": [
    "def grad_check(f,xy0,delta=1e-6,tolerance=1e-7):\n",
    "    f0,g0 = f(xy0)\n",
    "    p = len(xy0)\n",
    "    finite_diff = np.zeros(p)\n",
    "    gradient_correct = True\n",
    "    for i in range(p):\n",
    "        xy1 = np.copy(xy0)\n",
    "        xy2 = np.copy(xy0)\n",
    "        xy1[i] = xy1[i] - 0.5*delta\n",
    "        xy2[i] = xy2[i] + 0.5*delta\n",
    "        f1,_ = f(xy1)\n",
    "        f2,_ = f(xy2)\n",
    "        finite_diff = (f2 - f1)/(delta)\n",
    "        if (abs(finite_diff - g0[i])>tolerance):\n",
    "            print(\"Broken partial\",i,\" Finite Diff: \",\n",
    "                  finite_diff,\" Partial: \",g0[i])\n",
    "            gradient_correct = False\n",
    "    return gradient_correct\n",
    "\n",
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0\n",
    "g = lambda xy0: loglikelihood(xy0, X=train_data_pad[:,:15], y=trainLabel, alpha=1)\n",
    "\n",
    "did_u_pass = grad_check( g, w_init[:15], delta=1e-6, tolerance=1e-5 )\n",
    "\n",
    "print(f\"Passed test? {did_u_pass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Gradient ascent fine-tuning\n",
    "We provide you with the gradient ascent function in the cell below. (ur welcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(f,x,init_step,iterations):  \n",
    "    f_val,grad = f(x)                           # compute function value and gradient \n",
    "    f_vals = [f_val]\n",
    "    for it in range(iterations):                # iterate for a fixed number of iterations\n",
    "        done = False                            # initial condition for done\n",
    "        line_search_it = 0                      # how many times we tried to shrink the step\n",
    "        step = init_step                        # reset step size to the initial size\n",
    "        while not done and line_search_it<100:  # are we done yet?\n",
    "            new_x = x + step*grad               # take a step along the gradient\n",
    "            new_f_val,new_grad = f(new_x)       # evaluate function value and gradient\n",
    "            if new_f_val<f_val:                 # did we go too far?\n",
    "                step = step*0.95                # if so, shrink the step-size\n",
    "                line_search_it += 1             # how many times did we shrank the step\n",
    "            else:\n",
    "                done = True                     # better than the last x, so we move on\n",
    "        \n",
    "        if not done:                            # did not find right step size\n",
    "            print(\"Line Search failed.\")\n",
    "        else:\n",
    "            f_val = new_f_val                   # ah, we are ok, accept the new x\n",
    "            x = new_x\n",
    "            grad = new_grad\n",
    "            f_vals.append(f_val)\n",
    "        plt.plot(f_vals)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Function value')\n",
    "    return f_val, x\n",
    "\n",
    "np.random.seed(12345)\n",
    "w_init = np.random.randn( train_data_pad.shape[1] )*0.001\n",
    "w_init[0] = 0\n",
    "\n",
    "def optimizeFn( init_step, iterations, alpha, w):\n",
    "    g = lambda xy0: loglikelihood(xy0, train_data_pad, trainLabel, alpha)\n",
    "    f_val, update_w = gradient_ascent( g, w, init_step, iterations )\n",
    "    return f_val, update_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) **<span style='background :yellow'>(1pt)</span>** <font color=blue> In the cell below, try three different values (1e-5, 1e-6, and 1e-7) for the `init_step` variable. Then, in the provided \"ANSWER\" cell, report the final regularized log-likelihood for each of the three `init_step` values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "-6477.459028629964\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_val, update_w = optimizeFn( init_step = 10**-7, iterations=100, alpha=0, w = w_init)\n",
    "%time\n",
    "print(f_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ANSWER to Q8:* \n",
    "<font color=blue>\n",
    "    \n",
    "* Final $P\\mathcal{L}\\mathcal{L}$ for 1e-5 = -3033.038248915222\n",
    "* Final $P\\mathcal{L}\\mathcal{L}$ for 1e-6 = -4707.155301132124\n",
    "* Final $P\\mathcal{L}\\mathcal{L}$ for 1e-7 = -6477.459028629964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Prediction, hyperparameter tuning, and evaluation\n",
    "\n",
    "To evaluate the performance of our model we need to have a prediction function. This function will use our trained model to predict whether reviews are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) **<span style='background :yellow'>(1pt)</span>** <font color=blue> In the cell below, replace the ellipses (three of them) with code to complete the `prediction` function. The inputs are (1) feature weights and (2) the feature matrix. The return value is a vector of predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, validData ):\n",
    "    prob = 1./(1+np.exp( -(validData.dot(w))  ))         ## FILL-IN-THE-BLANK ## \n",
    "    res = np.zeros(validData.shape[0])\n",
    "    res[prob>=.5] = 1                ## FILL-IN-THE-BLANK ## \n",
    "    res[prob<.5] = -1                 ## FILL-IN-THE-BLANK ## \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) **<span style='background :yellow'>(1pt)</span>** <font color=blue> In the cell below, try different values for the `alpha` variable (1000, 2000, 3000). Then, in the provided \"ANSWER\" cell, report which of the three produces the model that has the best accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Search failed.\n",
      "Line Search failed.\n",
      "Line Search failed.\n",
      "Line Search failed.\n",
      "Line Search failed.\n",
      "Line Search failed.\n",
      "Accuracy on the validation set: 84.72%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_val, update_w=optimizeFn( init_step = 1e-5, iterations=100, alpha=3000, w=w_init)\n",
    "pred = prediction(update_w, valid_data_pad)\n",
    "print( 'Accuracy on the validation set: {:.2f}%'.format( 100.*np.mean(pred==validLabel)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ANSWER to Q10:* \n",
    "<font color=blue> \n",
    "The best alpha is 3000, and the accuracy of this alpha is 84.72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) **<span style='background :yellow'>(1pt)</span>** <font color=blue> We would like to know which samples in the validation set are misclassifed with high probability (that is, >90%).\n",
    "    \n",
    "<font color=blue>To accomplish this you must replace the ellipses with code, in the cell below, to implement `computeProb`. Additionally, you must write code to retrieve indices of samples that are misclassified; these indices are designated as `wrong_idx_high` in the cell below.\n",
    "      \n",
    "<font color=blue>After writing your code, report the indices for all samples that result in high-confidence misclassifcations in the provided \"ANSWER\" cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2027 2257 3204]\n"
     ]
    }
   ],
   "source": [
    "# Command to get the samples that are predicted wrong\n",
    "wrong_idx = np.nonzero( validLabel != pred )[0]\n",
    "\n",
    "# Function to compute probability\n",
    "def computeProb(w, validData ):\n",
    "    prob = 1./(1+np.exp( -(validData.dot(w)) ))  ## FILL-IN-THE-BLANK ## \n",
    "    return prob\n",
    "\n",
    "# Get samples that are classified wrong and with probabilites > 0.9\n",
    "probs = computeProb(update_w, valid_data_pad)\n",
    "wrong_idx_high = np.intersect1d(wrong_idx, np.where(probs>0.9))          ## FILL-IN-THE-BLANK ## \n",
    "print(wrong_idx_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ANSWER to Q11:* \n",
    "<font color=blue>\n",
    "    \n",
    "The indices corresponding to high-confidence misclassified samples are 2027, 2257, 3204  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) **<span style='background :yellow'>(1pt)</span>** <font color=blue> Choose one of the misclassified indices from above and set it equal to `sampleIdx` in the cell below. Then in the provided \"ANSWER\" cell, report the words (entries in `vocab_list` associated with that feature) that cause the selected sample  to be misclassified. </font> (Just fyi: Weight $w[i]$ correponds to word `vocab_list[i-1]`, because we included bias term in $w$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['favorite', 'songs', 'could', 'great', 'nothing', 'loved', 'perfect', 'completely', 'us', 'think']\n"
     ]
    }
   ],
   "source": [
    "sampleIdx = wrong_idx_high[0]\n",
    "\n",
    "# This function returns a list of top 10 words that influence the prediction.\n",
    "def getMostImportantFeatures( sampleIdx, validData, update_w, vocab_list ):\n",
    "    confusedList = []\n",
    "    intensity = validData[[sampleIdx],:]*update_w\n",
    "    tmp = np.argsort( np.abs(intensity[0,:]) )[::-1]\n",
    "    for j in np.arange(10):\n",
    "        confusedList.append(vocab_list[tmp[j]-1])\n",
    "    return confusedList\n",
    "\n",
    "confusedList = getMostImportantFeatures( sampleIdx, valid_data_pad, update_w, vocab_list)\n",
    "print(confusedList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *ANSWER to Q12:* \n",
    "<font color=blue>\n",
    "    \n",
    "The \"confusing\" words for the chosen review are 'favorite', 'songs', 'could', 'great', 'nothing', 'loved', 'perfect', 'completely', 'us', 'think' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, you can read the review (by going to the URL printed below) and check if it is hard to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://wwwx.cs.unc.edu/Courses/comp755-f18/hw1/reviews/9588_4.txt\n"
     ]
    }
   ],
   "source": [
    "train_id = pickle.load( gzip.open( \"train_id.pgz\", \"rb\" ) )\n",
    "valid_id = train_id[10000:15000]\n",
    "\n",
    "fileName = valid_id[sampleIdx]\n",
    "fileUrl = \"https://wwwx.cs.unc.edu/Courses/comp755-f18/hw1/reviews/\" + fileName + '.txt'\n",
    "print(fileUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
